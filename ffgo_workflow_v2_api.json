{
  "6": {
    "inputs": {
      "text": "A man walking in the park while the camera zooms in on his Nike sneakers throughout the scene",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œåœºæ™¯åˆ‡æ¢,ç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "137",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "DecodificaciÃ³n VAE"
    }
  },
  "38": {
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Cargar CLIP"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Cargar VAE"
    }
  },
  "54": {
    "inputs": {
      "shift": 8,
      "model": [
        "69",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "MuestreoDeModeloSD3"
    }
  },
  "55": {
    "inputs": {
      "shift": 8,
      "model": [
        "68",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "MuestreoDeModeloSD3"
    }
  },
  "56": {
    "inputs": {
      "unet_name": "wan2.2_i2v_low_noise_14B_fp16.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Cargar Modelo de DifusiÃ³n"
    }
  },
  "57": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": 100484965227664,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "lcm",
      "scheduler": "simple",
      "start_at_step": 0,
      "end_at_step": 3,
      "return_with_leftover_noise": "enable",
      "model": [
        "54",
        0
      ],
      "positive": [
        "135",
        0
      ],
      "negative": [
        "135",
        1
      ],
      "latent_image": [
        "135",
        2
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Avanzado)"
    }
  },
  "58": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": 549423873536358,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "lcm",
      "scheduler": "simple",
      "start_at_step": 3,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "55",
        0
      ],
      "positive": [
        "135",
        0
      ],
      "negative": [
        "135",
        1
      ],
      "latent_image": [
        "57",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Avanzado)"
    }
  },
  "63": {
    "inputs": {
      "lora_name": "I2V_lightx_4Steps_HIGH.safetensors",
      "strength_model": 1,
      "model": [
        "71",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "CargadorLoRAModeloSolo"
    }
  },
  "67": {
    "inputs": {
      "frame_rate": 60,
      "loop_count": 0,
      "filename_prefix": "AnimateDiff",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 16,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "161",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "68": {
    "inputs": {
      "sage_attention": "auto",
      "allow_compile": false,
      "model": [
        "74",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "69": {
    "inputs": {
      "nag_scale": 11,
      "nag_alpha": 0.25,
      "nag_tau": 2.5,
      "input_type": "default",
      "model": [
        "70",
        0
      ],
      "conditioning": [
        "135",
        1
      ]
    },
    "class_type": "WanVideoNAG",
    "_meta": {
      "title": "WanVideoNAG"
    }
  },
  "70": {
    "inputs": {
      "model": [
        "72",
        0
      ]
    },
    "class_type": "CFGZeroStar",
    "_meta": {
      "title": "CFGZeroStar"
    }
  },
  "71": {
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_fp16.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Cargar Modelo de DifusiÃ³n"
    }
  },
  "72": {
    "inputs": {
      "lora_name": "Wan22_FFGO-LoRA-HIGH_bf16.safetensors",
      "strength_model": 1,
      "model": [
        "63",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "CargadorLoRAModeloSolo"
    }
  },
  "74": {
    "inputs": {
      "lora_name": "Wan22_FFGO-LoRA-LOW_bf16.safetensors",
      "strength_model": 1,
      "model": [
        "133",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "CargadorLoRAModeloSolo"
    }
  },
  "93": {
    "inputs": {
      "width": [
        "112",
        0
      ],
      "height": [
        "114",
        0
      ],
      "upscale_method": "nearest-exact",
      "keep_proportion": "crop",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 2,
      "device": "cpu",
      "image": [
        "95",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "Resize Image v2"
    }
  },
  "95": {
    "inputs": {
      "start_index": -1,
      "num_frames": 1,
      "images": [
        "132",
        0
      ]
    },
    "class_type": "GetImageRangeFromBatch",
    "_meta": {
      "title": "Get Image or Mask Range From Batch"
    }
  },
  "111": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "158",
        0
      ],
      "image": [
        "93",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "112": {
    "inputs": {
      "value": 1280
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "width"
    }
  },
  "114": {
    "inputs": {
      "value": 1024
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "height"
    }
  },
  "122": {
    "inputs": {
      "image": "zapa1.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Cargar Imagen_1"
    }
  },
  "125": {
    "inputs": {
      "image": "zapa2.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Cargar Imagen_2"
    }
  },
  "126": {
    "inputs": {
      "image": "zapa3.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Cargar Imagen_3"
    }
  },
  "127": {
    "inputs": {
      "model": "RMBG-2.0",
      "sensitivity": 1,
      "process_res": 1024,
      "mask_blur": 0,
      "mask_offset": 0,
      "invert_output": false,
      "refine_foreground": false,
      "background": "Color",
      "background_color": "#ffffff",
      "image": [
        "126",
        0
      ]
    },
    "class_type": "RMBG",
    "_meta": {
      "title": "Remove Background (RMBG)"
    }
  },
  "128": {
    "inputs": {
      "direction": "down",
      "match_image_size": true,
      "spacing_width": 0,
      "spacing_color": "white",
      "image1": [
        "127",
        0
      ],
      "image2": [
        "162",
        0
      ]
    },
    "class_type": "ImageStitch",
    "_meta": {
      "title": "Image Stitch"
    }
  },
  "129": {
    "inputs": {
      "direction": "right",
      "match_image_size": true,
      "spacing_width": 0,
      "spacing_color": "white",
      "image1": [
        "128",
        0
      ],
      "image2": [
        "122",
        0
      ]
    },
    "class_type": "ImageStitch",
    "_meta": {
      "title": "Image Stitch"
    }
  },
  "131": {
    "inputs": {
      "images": [
        "132",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Vista previa de imagen"
    }
  },
  "132": {
    "inputs": {
      "width": [
        "112",
        0
      ],
      "height": [
        "114",
        0
      ],
      "upscale_method": "lanczos",
      "keep_proportion": "pad",
      "pad_color": "255,255,255",
      "crop_position": "center",
      "divisible_by": 16,
      "device": "cpu",
      "image": [
        "129",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "Resize Image v2"
    }
  },
  "133": {
    "inputs": {
      "lora_name": "I2V_lightx_4Steps_LOW.safetensors",
      "strength_model": 1,
      "model": [
        "56",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "CargadorLoRAModeloSolo"
    }
  },
  "135": {
    "inputs": {
      "width": [
        "112",
        0
      ],
      "height": [
        "114",
        0
      ],
      "length": 81,
      "batch_size": 1,
      "motion_amplitude": 1.15,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "39",
        0
      ],
      "clip_vision_output": [
        "111",
        0
      ],
      "start_image": [
        "93",
        0
      ]
    },
    "class_type": "PainterI2V",
    "_meta": {
      "title": "PainterI2V"
    }
  },
  "137": {
    "inputs": {
      "trim_amount": 4,
      "samples": [
        "58",
        0
      ]
    },
    "class_type": "TrimVideoLatent",
    "_meta": {
      "title": "TrimVideoLatent"
    }
  },
  "158": {
    "inputs": {
      "clip_name": "clip_vision_h.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Cargar CLIP Vision"
    }
  },
  "161": {
    "inputs": {
      "ckpt_name": "rife47.pth",
      "clear_cache_after_n_frames": 10,
      "multiplier": 4,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1,
      "frames": [
        "8",
        0
      ]
    },
    "class_type": "RIFE VFI",
    "_meta": {
      "title": "RIFE VFI (recommend rife47 and rife49)"
    }
  },
  "162": {
    "inputs": {
      "model": "RMBG-2.0",
      "sensitivity": 1,
      "process_res": 1024,
      "mask_blur": 0,
      "mask_offset": 0,
      "invert_output": false,
      "refine_foreground": false,
      "background": "Color",
      "background_color": "#ffffff",
      "image": [
        "125",
        0
      ]
    },
    "class_type": "RMBG",
    "_meta": {
      "title": "Remove Background (RMBG)"
    }
  }
}